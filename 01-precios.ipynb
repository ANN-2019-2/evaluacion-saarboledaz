{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "n3lnWjvI83ix"
   },
   "source": [
    "# Pronóstico adaptativo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Descripción del problema real"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los pronósticos de los precios de la electricidad en mercados liberalizados son un insumo fundamental para la toma de decisiones dentro de las organizaciones. Fundamentalmente, los pronosticos de corto plazo son utilizados en decisiones de carácter operativo. En el caso abordado, es necesario contar con los pronósticos para definir la politica de operación de una empresa del sector eléctrico."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Descripción del problema en términos de los datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La carpeta `datos/precios/` contiene los precios historicos horarios de la electricidad en la Bolsa de Energía del mercado eléctrico colombiano, publicados por el operador del mercado. Se desean obtener pronósticos para el precio promedio diario para los próximos siete (7) días a la fecha actual."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aproximaciones posibles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este caso, se desea evaluar la capacidad de pronóstico de un ADALINE con aprendizaje en línea."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Requerimientos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usted debe:\n",
    "\n",
    "* Procesar los datos históricos para conformar el conjunto de datos. Los archivos de Excel no pueden ser modificados y actualizados directamente por el operador del sistema. Su código debe leer los archivos y crear la serie de precios promedio diarios de la electricidad.\n",
    "\n",
    "\n",
    "* Determinar si el modelo debe pronosticar los precios promedios sin ninguna transformación, o si la inclusión de una transformación (logaritmo natural, raíz cúbica, raíz cuadrada, etc) resulta en un incremento de la precisión del pronóstico.\n",
    "\n",
    "\n",
    "* Generar el pronóstico para los precios de los próximos siete días.\n",
    "\n",
    "\n",
    "* Preparar el código para que el modelo sea entrenado usando el gradiente y el momentum.\n",
    "\n",
    "\n",
    "* Determinar cuál es el número óptimo de retardos (observaciones) que el modelo debe considerar hacia atrás para producir el pronóstico.\n",
    "\n",
    "\n",
    "* Determinar los valores óptimos de la tasa de aprendizaje y el momentum.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Librerías de uso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import datetime as dt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocesamiento de los datos\n",
    "Para el preprocesamiento de los datos fue necesario añadir varias excepciones para la lectura de datos, ya que el formato de \n",
    "estos no era consistente en su totalidad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = './datos/precios/Precio_Bolsa_Nacional_($kwh)_'\n",
    "\n",
    "complete_df = None\n",
    "for year in range(1995,2019):\n",
    "    extension = 'xlsx'\n",
    "    if (year >= 2016):\n",
    "        extension = 'xls'\n",
    "    filestring = file_path + str(year) +'.'+ extension\n",
    "    skiprows=3\n",
    "    if (year >= 2000):\n",
    "        skiprows = 2\n",
    "    df = pd.read_excel(filestring,skiprows=skiprows)\n",
    "    means = []\n",
    "    df = df.dropna(axis='index', thresh=10)\n",
    "    df = df.dropna(axis='columns', how='all')\n",
    "    for index, row in df.iterrows():\n",
    "        s = 0\n",
    "        c = 0\n",
    "        for i in range(0,24):\n",
    "            value = row[str(i)]\n",
    "            if (not pd.isnull(value)):\n",
    "                s += float(value)\n",
    "                c += 1\n",
    "        prom = s/c\n",
    "        means.append(prom)\n",
    "    df['Mean'] = means\n",
    "    if (year == 1995):\n",
    "        complete_df = df\n",
    "    else:\n",
    "        complete_df = complete_df.append(df)\n",
    "parsed_dates = []\n",
    "for d in complete_df['Fecha'].values:\n",
    "    if (isinstance(d,str)):\n",
    "        parsed_dates.append(dt.datetime.strptime(d,\"%Y-%m-%d\"))\n",
    "    elif (isinstance(d,dt.datetime)):\n",
    "        parsed_dates.append(d)\n",
    "    else:\n",
    "        print(d)\n",
    "        print(type(d))\n",
    "complete_df['Parse Date'] = pd.to_datetime(parsed_dates)\n",
    "\n",
    "complete_df['Timestamp'] = [d.timestamp() for d in parsed_dates]\n",
    "complete_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vista previa de los datos originales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gráfica de la tendencia promedio de los precios\n",
    "\n",
    "Se realiza una gráfica para observar el comportamiento de los precios a lo largo de los años, se identifica el gran pico en la crisis energética de 2016"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_df.sort_values(by='Parse Date')\n",
    "complete_df.drop_duplicates(subset=\"Parse Date\", keep=\"first\", inplace=True)\n",
    "plt.figure(figsize=(20,5))\n",
    "plt.title('Precio de la Energía')\n",
    "plt.xlabel('Año')\n",
    "plt.ylabel('COP')\n",
    "plt.plot(complete_df['Parse Date'], complete_df['Mean'], color='red')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IPC \n",
    "Es necesario normalizar los datos multiplicandolos por el IPC histórico y así poder descartar la inflación como variable de cambio, para esto se hará uso del archivo de excel 'ipc_historico.xlsx, que también se encuentra en la carpeta de datos, este archivo se obtuvo de la página web del <a href=\"https://www.banrep.gov.co/es/estadisticas/indice-precios-consumidor-ipc\" target=\"_blank\">Banco de la República</a>  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ipc_df = pd.read_excel('./datos/precios/series_ipc_historico.xlsx', skiprows=12, parse_dates=True)\n",
    "ipc_df = ipc_df.dropna(axis='index', thresh=2)\n",
    "ipc_df = ipc_df.dropna(axis='columns', how='all')\n",
    "ipc_df['Parse Date'] = [dt.datetime.strptime(str(d),\"%Y%m\") for d in ipc_df['Año(aaaa)-Mes(mm)'].tolist()]\n",
    "ipc_df.sort_values(by='Parse Date', inplace=True)\n",
    "ipc_df.tail()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Obtenemos el IPC base\n",
    "mask = (ipc_df['Índice'] == 100)\n",
    "base_ipc_df = ipc_df.loc[mask]\n",
    "base_ipc_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_ipc = base_ipc_df['Índice'].tolist()[0]\n",
    "print(base_ipc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized_means = []\n",
    "for m,d in zip(complete_df['Mean'].tolist(), complete_df['Timestamp'].tolist()):\n",
    "    date = dt.datetime.utcfromtimestamp(d)\n",
    "    mask = (ipc_df['Parse Date'].dt.year == date.year) & (ipc_df['Parse Date'].dt.month == date.month)\n",
    "    ipc = ipc_df.loc[mask]['Índice'].values[0]\n",
    "    normalized_price = m * (base_ipc/ipc)\n",
    "    normalized_means.append(normalized_price)\n",
    "\n",
    "complete_df['Precio Normalizado'] = normalized_means    \n",
    "\n",
    "complete_df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparación de Precio vs Precio Normalizado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,5))\n",
    "plt.title('Precio de la Energía')\n",
    "plt.xlabel('Año')\n",
    "plt.ylabel('COP')\n",
    "plt.plot(complete_df['Parse Date'], complete_df['Mean'], label=\"Precio\", color='red')\n",
    "plt.plot(complete_df['Parse Date'], complete_df['Precio Normalizado'], label=\"Precio Normalizado\", color='black')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transformación de los Datos\n",
    "Finalizado el proceso de preprocesamiento, se conformará un nuevo dataframe con los datos estrictamente necesarios, y una a una se irán agregando las transformaciones a los precios normalizados. Las transformaciones a usar serán:\n",
    "<ul>\n",
    "    <li>Logaritmo natural</li>\n",
    "    <li>Raíz cuadrada</li>\n",
    "    <li>Raíz cúbica</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform(values,trans, inverse = False):\n",
    "    if (not inverse):\n",
    "        if (trans == \"Log_Natural\"):\n",
    "            return np.log(values)\n",
    "        elif (trans == \"Raiz_Cuadrada\"):\n",
    "            return np.sqrt(values)\n",
    "        elif (trans == \"Raiz_Cubica\"):\n",
    "            return np.cbrt(values)\n",
    "    else:\n",
    "        if (trans == \"Log_Natural\"):\n",
    "            return np.exp(values)\n",
    "        elif (trans == \"Raiz_Cuadrada\"):\n",
    "            return np.power(values,2)\n",
    "        elif (trans == \"Raiz_Cubica\"):\n",
    "            return np.power(values,4)\n",
    "\n",
    "##Nuevo dataframe solo con los datos requeridos\n",
    "df_dict = {\n",
    "    \"Fecha\": complete_df['Parse Date'],\n",
    "    \"Timestamp\": complete_df['Timestamp'],\n",
    "    \"Precio_Promedio\": complete_df['Mean'],\n",
    "    \"Precio_Normalizado\": complete_df['Precio Normalizado']\n",
    "}\n",
    "df = pd.DataFrame(df_dict)\n",
    "transformations = ['Log_Natural','Raiz_Cuadrada', 'Raiz_Cubica']\n",
    "for t in transformations:\n",
    "    ##Le agregamos las distintas transformaciones al precio normalizado\n",
    "    df[t] = transform(df['Precio_Normalizado'],t)\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gráfica comparativa de cada una de las transformaciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,5))\n",
    "plt.title('Precio de la Energía')\n",
    "plt.xlabel('Año')\n",
    "plt.ylabel('Valor')\n",
    "#plt.plot(df['Fecha'], df['Precio_Normalizado'], label=\"Precio Normalizado\", color='black')\n",
    "plt.plot(df['Fecha'], df['Log_Natural'], label=\"Log Natural\", color='red')\n",
    "plt.plot(df['Fecha'], df['Raiz_Cuadrada'], label=\"Raíz Cuadrada\", color='green')\n",
    "plt.plot(df['Fecha'], df['Raiz_Cubica'], label=\"Raíz Cúbica\", color='blue')\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Elección de la Transformación\n",
    "\n",
    "Para elegir la transformación adecuada se realizará el modelo, se hará un pronóstico y se seleccionará aquella transformación con menor error\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementación del Modelo\n",
    "\n",
    "La implementación del modelo escogida es la propuesta por el profesor en el siguiente <a href=\"https://jdvelasq.github.io/courses/notebooks/tensorflow/adaline/1-01-adalines.html\" target=\"_blank\">enlace</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Adaline:\n",
    "    def __init__(self,\n",
    "                 learning_rate=0.001, # tasa de aprendizaje\n",
    "                 momentum=0,      # Momentum               \n",
    "                 max_epochs=100,      # número máximo de iteraciones sobre el set de datos\n",
    "                 shuffle=False,       # mezcla patrones para aprendizaje online\n",
    "                 random_state=None,   #\n",
    "                 warm_start=False):   #\n",
    "        \n",
    "        self.momentum = momentum\n",
    "        self.learning_rate = learning_rate\n",
    "        self.max_epochs = max_epochs\n",
    "        self.shuffle = shuffle\n",
    "        self.random_state = random_state\n",
    "        self.warm_start = warm_start\n",
    "        self.coef_ = None\n",
    "        self.intercept_ = None\n",
    "\n",
    "    def fit(self, X, y):\n",
    "\n",
    "        if not isinstance(X, np.ndarray):\n",
    "            X = np.array(X)\n",
    "        if not isinstance(y, np.ndarray):\n",
    "            d = np.array(y)\n",
    "        else:\n",
    "            d = y.copy()\n",
    "\n",
    "        if self.random_state is not None:\n",
    "            np.random.RandomState(self.random_state)\n",
    "\n",
    "        if self.coef_ is None or self.warm_start is False:\n",
    "            self.coef_ = np.random.uniform(-1, 1, X.shape[1])\n",
    "\n",
    "        if self.intercept_ is None  or self.warm_start is False:\n",
    "            self.intercept_ = np.random.uniform(-1, 1, 1)\n",
    "\n",
    "        errors2 = []\n",
    "        forecasts = []\n",
    "\n",
    "        for epoch in range(self.max_epochs):\n",
    "\n",
    "            if self.shuffle is True:\n",
    "                n = list(range(X.shape[0]))\n",
    "                np.random.shuffle(n) #Desordena una lista de indices\n",
    "                X = X[n,:] \n",
    "                d = d[n]\n",
    "\n",
    "            for i in range(X.shape[0]):\n",
    "                u = np.dot(X[i,:], self.coef_) + self.intercept_ \n",
    "                e = (d[i] - u)[0]\n",
    "                ## Se agrega el momentum al coeficiente e intercepto\n",
    "                self.coef_ += 2 * self.learning_rate * e * X[i,:] + self.coef_ * self.momentum\n",
    "                self.intercept_ += 2 * self.learning_rate * e + self.intercept_*self.momentum\n",
    "                errors2.append(e**2)\n",
    "                forecasts.append(u)\n",
    "\n",
    "        return errors2, forecasts\n",
    "\n",
    "    def predict(self, X):\n",
    "        if not isinstance(X, np.ndarray):\n",
    "            X = np.array(X)\n",
    "        u = np.dot(X, self.coef_) + self.intercept_\n",
    "        return u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformations = ['Log_Natural', 'Raiz_Cuadrada', 'Raiz_Cubica']\n",
    "L = 7\n",
    "scalers = dict() ## Scalers para cada transformación\n",
    "desireds_d = dict() ## Deseados \n",
    "forecasts_d = dict() ## Pronóstico\n",
    "errors2_d = dict() ## errores\n",
    "\n",
    "## Realizar el pronóstico para cada transformación\n",
    "for trans in transformations:\n",
    "    scaler = MinMaxScaler() ##Scaler\n",
    "    d = np.asarray(df[trans]).reshape(-1,1)\n",
    "    scaler.fit(d)\n",
    "    scaled_d = scaler.transform(d).ravel() ##Usar los valores escalados entre 0 y 1 \n",
    "    scalers[trans] = scaler\n",
    "    desireds_d[trans] = d\n",
    "    X = []\n",
    "    for t in range(L, len(d)):\n",
    "        X.append(scaled_d[t-L:t].copy())\n",
    "        \n",
    "    adaline = Adaline(\n",
    "    learning_rate=0.001, \n",
    "    max_epochs=1,        \n",
    "    shuffle=False,       \n",
    "    random_state=123,    \n",
    "    warm_start=False)    \n",
    "    \n",
    "    errors2, forecasts = adaline.fit(X,scaled_d[L:])\n",
    "    forecasts_d[trans] = scaler.inverse_transform(np.asarray(forecasts).reshape(-1,1)).ravel() ##Regresar a la escala\n",
    "    errors2_d[trans] = errors2\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,15)) \n",
    "for i in range(len(transformations)):\n",
    "    trans = transformations[i]\n",
    "    plt.subplot(3,1,i+1)   \n",
    "    plt.xlabel('Año')\n",
    "    plt.ylabel('Valor')\n",
    "    plt.plot(desireds_d[trans], label=trans, color='black')\n",
    "    plt.plot(range(L, len(desireds_d[trans])),forecasts_d[trans], label=\"Pronóstico\", color='red')\n",
    "    plt.legend()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se observa que todas las transformaciones tienen un comportamiento similar, un poco errático por la alta variación de los datos. Entre estas la que más destaca es la transformación de Log_Natural, de igual manera se realizará el análisis modificando las tasa de aprendizaje y otros valores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Aplicando la transformación inversa\n",
    "forecast_inv = dict()\n",
    "for t in transformations:\n",
    "    forecast_inv[t] = transform(forecasts_d[t],t,True)\n",
    "\n",
    "plt.figure(figsize=(20,5))\n",
    "plt.title('Precio de la Energía')\n",
    "plt.xlabel('Año')\n",
    "plt.ylabel('Valor')\n",
    "first_date = dt.datetime.utcfromtimestamp(df['Timestamp'].tolist()[0])\n",
    "date_thresh = (df['Fecha'] >= first_date + dt.timedelta(L-1))\n",
    "dates_df = df.loc[date_thresh]['Fecha']\n",
    "plt.plot(df['Fecha'],df['Precio_Normalizado'], label=\"Precio_Normalizado\", color='black')\n",
    "plt.plot(dates_df,forecast_inv[\"Log_Natural\"], label=\"Pronósitco Log\", color='red')\n",
    "plt.plot(dates_df,forecast_inv[\"Raiz_Cubica\"], label=\"Pronóstico Raiz3\", color='blue')\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Realizando la comparación se puede notar que las transformaciones tienen un comportamiento similar, ahora se procederá a evaluar el error."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Separación de Datos (Predicción y Entrenamiento)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = ['Precio_Normalizado'] +transformations\n",
    "\n",
    "aux_scaler = MinMaxScaler()\n",
    "aux_scaler.fit(np.asarray(df['Precio_Normalizado']).reshape(-1,1))\n",
    "scalers['Precio_Normalizado'] = aux_scaler ##Agregamos el scaler para el precio normalizado\n",
    "\n",
    "n = df['Precio_Normalizado'].size \n",
    "\n",
    "\n",
    "train_df = pd.DataFrame(columns=models) ##Dataframe de entrenamiento\n",
    "\n",
    "predict = df.iloc[(n - 7):]['Precio_Normalizado'] ##Datos a predecir\n",
    "for model in models: \n",
    "    train_df[model] = df[model][:(n-7)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se guardan los resultados de los errores del modelo en un dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ls= list(range(7, 14)) #Latencia\n",
    "result_df = pd.DataFrame(columns = [\"Modelo\",\"E_Pronostico\",\"E_Entrenamiento\",\"L\",\"Momentum\",\"Tasa_Apr\",\"Pronosticos\"])\n",
    "\n",
    "for model in models:\n",
    "    d = np.asarray(train_df[model]).reshape(-1,1)\n",
    "    scaler = scalers[model]\n",
    "    d = scaler.transform(d).ravel() #Datos para usar en el modelo\n",
    "    for L in Ls:\n",
    "        for momentum in np.arange(0.00000, 0.0001,0.000025): #Se eligieron valores muy bajos del momentum porque variaba demasiado\n",
    "            for learning_rate in np.arange(0.005, 0.1, 0.005):\n",
    "                X = []\n",
    "                P = []\n",
    "                for t in range(L,len(d)):\n",
    "                    X.append(d[t-L:t].copy())\n",
    "\n",
    "                #Se entrena el modelo\n",
    "                adaline = Adaline(\n",
    "                    learning_rate=learning_rate, \n",
    "                    momentum = momentum,  \n",
    "                    shuffle=False,       \n",
    "                    random_state=123,    \n",
    "                    warm_start=False)    \n",
    "                errors2, forecasts = adaline.fit(X, d[L:])\n",
    "\n",
    "                #Pronóstico\n",
    "                for i in range(7):\n",
    "                    u = adaline.predict(X[-1]) #Predicción proximo valor\n",
    "                    next_X = np.append(X[-1][1:L], [u]) #Se agrega el nuevo pronóstico\n",
    "                    X = np.concatenate( ( X, [next_X] ), axis=0) \n",
    "                    P.append(u[0]) #Almacena el pronóstico\n",
    "\n",
    "                #Invertir la transformación de escalado    \n",
    "                P = scaler.inverse_transform(np.asarray(P).reshape(-1,1)).ravel() \n",
    "                forecasts = scaler.inverse_transform(np.asarray(forecasts).reshape(-1,1)).ravel() \n",
    "                \n",
    "                #Invertir la transformación aplicada\n",
    "                if (model != 'Precio_Normalizado'):\n",
    "                    P = transform(P,model,True)  \n",
    "                    forecasts = transform(forecasts,model,True)\n",
    "\n",
    "                e_p = np.sum(np.power(np.array(predict) - P, 2))   \n",
    "                e = np.sum(errors2)\n",
    "                #Guardar valores del pronóstico\n",
    "                result_df = result_df.append({\n",
    "                    \"Modelo\": model,\n",
    "                    \"E_Pronostico\": e_p,\n",
    "                    \"E_Entrenamiento\": e,\n",
    "                    \"L\": L,\n",
    "                    \"Momentum\": momentum,\n",
    "                    \"Tasa_Apr\": learning_rate,\n",
    "                    \"Pronosticos_E\":forecasts,\n",
    "                    \"Pronosticos\": P,\n",
    "                },ignore_index=True)\n",
    "                \n",
    "result_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_predict = result_df[result_df.E_Pronostico == result_df.E_Pronostico.min()] ##Mejor pronóstico\n",
    "best_train = result_df[result_df.E_Entrenamiento == result_df.E_Entrenamiento.min()] ##Mejor entrenamiento\n",
    "\n",
    "best_predict.head() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelo seleccionado\n",
    "Finalmente se selecciona el modelo con un menor error de entrenamiento para realizar la predicción de los próximos 7 días. De igual forma se grafica el modelo con el mejor pronóstico para contemplar el comportamiento del pronóstico realizado vs el real, donde se puede observar un comportamiento casi similar en cuestión de subida y caída del precio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,5))\n",
    "plt.title('Precio de la Energía')\n",
    "plt.xlabel('Año')\n",
    "plt.ylabel('Valor')\n",
    "plt.plot(predict.values, label=\"Datos\", color='black', marker='o', linestyle='dashed',linewidth=2, markersize=12)\n",
    "plt.plot(best_predict['Pronosticos'].values[0],label=\"Pronóstico\", color='red', marker='o', linestyle='dashed',linewidth=2, markersize=12)\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comportamiento general del Modelo\n",
    "\n",
    "Se gráfica el comportamiento general del modelo seleccionado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#forecasts_p = best_predict['Pronosticos_E'].values[0]\n",
    "forecasts_t = best_train['Pronosticos_E'].values[0]\n",
    "\n",
    "plt.figure(figsize=(20,5))\n",
    "plt.title('Precio de la Energía')\n",
    "plt.xlabel('Año')\n",
    "plt.ylabel('Valor')\n",
    "plt.plot(train_df['Precio_Normalizado'].values, label=\"Precio Real\", color = \"black\")\n",
    "plt.plot(forecasts_t, label=\"Pronóstico\", color=\"red\")\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pronóstico de los 7 días con el modelo escogido"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Se obtienen los datos del mejor pronóstico\n",
    "transformation = best_train['Modelo'].values[0]\n",
    "learning_rate = best_train['Tasa_Apr'].values[0]\n",
    "momentum =  best_train['Momentum'].values[0]\n",
    "L = best_train['L'].values[0]\n",
    "epochs = best_train['Epochs'].values[0]\n",
    "\n",
    "d = np.asarray(df[transformation]).reshape(-1,1)\n",
    "scaler = scalers[transformation]\n",
    "d = scaler.transform(d).ravel() ##Datos para usar en el modelo\n",
    "\n",
    "X = []\n",
    "P = []\n",
    "for t in range(L,len(d)):\n",
    "    X.append(d[t-L:t].copy())\n",
    "\n",
    "adaline = Adaline(\n",
    "    learning_rate=learning_rate,  \n",
    "    momentum = momentum, \n",
    "    max_epochs=epochs,        \n",
    "    shuffle=False,       \n",
    "    random_state=123,    \n",
    "    warm_start=False)    \n",
    "errors2, forecasts = adaline.fit(X, d[L:]) \n",
    "\n",
    "##Pronósticar los próximos 7 días\n",
    "for i in range(7):\n",
    "    u = adaline.predict(X[-1]) \n",
    "    next_X = np.append(X[-1][1:L], [u]) \n",
    "    X = np.concatenate( ( X, [next_X] ), axis=0)\n",
    "    forecasts.append(u[0]) \n",
    "    P.append(u[0])\n",
    "    \n",
    "forecasts = scaler.inverse_transform(np.asarray(forecasts).reshape(-1,1)).ravel()\n",
    "forecasts = transform(forecasts,model,True)\n",
    "P = scaler.inverse_transform(np.asarray(P).reshape(-1,1)).ravel()\n",
    "P = transform(P,model,True)\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comportamiento del Precio de la Energía para los próximos 7 días"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,5))\n",
    "plt.title('Precio de la Energía')\n",
    "plt.xlabel('Año')\n",
    "plt.ylabel('Valor')\n",
    "plt.plot(P, label=\"Pronóstico\", color=\"red\")\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "include_colab_link": true,
   "name": "Copia de Untitled3.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
